{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legal AI Chatbot (Type 'exit' or 'quit' to stop)\n",
      "\n",
      "AI: 1. I'm an assistant specializing in the Indian Penal Code (IPC). The section you provided is not a specific IPC section number but rather a part of the Indian Evidence Act and some amendments related to it.\n",
      "    - Details: This text describes various terms used in the context of criminal proceedings, like \"complainant,\" \"High Court,\" \"inquiry,\" \"investigation,\" etc., and an amendment made to section 53A of the Indian Evidence Act. Additionally, it mentions section 54 (Previous bad character not relevant, except in reply) and section 39 (Public to give information of certain offences).\n",
      "    - Related or defendable sections: Sections mentioned under section 39 of the Indian Evidence Act are related to offenses punishable under various sections of the IPC.\n",
      "    - Type of law: This text falls under Criminal Procedure Law and Evidence Law.\n",
      "\n",
      "AI: 1. The IPC section for murder is Section 302 - Murder.\n",
      "   2. Related or defendable sections include Section 304 (Culpable homicide not amounting to murder) and Section 308 (Attempt to murder).\n",
      "   3. The type of law it falls under is Criminal Law.\n",
      "\n",
      "AI: 1. Details: This text describes section 357 of the Indian Evidence Act, which pertains to the breach of contract to attend on and supply wants of a helpless person. The section states that whoever is bound by a lawful contract to attend on or supply the needs of a helpless person and voluntarily omits doing so shall be punished with imprisonment for a term which may extend to three months, or with fine which may extend to five thousand rupees, or with both.\n",
      "\n",
      "  2. Related or defendable sections: Sections related to this breach of contract are not explicitly mentioned in the provided text. However, it's important to note that this breach of contract is relevant under Indian law and falls under the category of criminal offenses.\n",
      "\n",
      "  3. Type of law: The text falls under Criminal Law and Evidence Law as it deals with a specific offense (breach of contract) and its associated penalties, as well as the provisions related to evidence in criminal proceedings.\n",
      "\n",
      "Exiting chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "CHROMA_DB_PATH = r\"C:\\Users\\suram\\OneDrive\\Desktop\\rag project\\chroma_db\"\n",
    "\n",
    "\\\n",
    "vectorstore = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embedding_model)\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=5, return_messages=True)\n",
    "\n",
    "\n",
    "system_message = SystemMessage(content=(\n",
    "    \"You are a legal assistant specializing in the Indian Penal Code (IPC). \"\n",
    "    \"When a user asks about an IPC section, provide: \"\n",
    "    \"(1) Details of the section, (2) Any related or defendable sections, \"\n",
    "    \"(3) The type of law it falls under (criminal, procedural, etc.). \"\n",
    "    \"If the user provides an IPC section number, directly return its details, \"\n",
    "    \"defendable sections, and classification. Ensure responses are clear, \"\n",
    "    \"concise, and legally accurate.\"\n",
    "))\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"retrieved_context\", \"query\"],\n",
    "    template=(\n",
    "        \"The following is a conversation between a user and a legal AI assistant:\\n\"\n",
    "        \"{history}\\n\\n\"\n",
    "        \"Retrieved Legal Context:\\n{retrieved_context}\\n\\n\"\n",
    "        \"User: {query}\\n\"\n",
    "        \"AI:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "retriever = (\n",
    "    RunnablePassthrough()\n",
    "    | (lambda query: embedding_model.embed_query(query))\n",
    "    | (lambda query_embedding: vectorstore.similarity_search_by_vector(query_embedding, k=3))\n",
    "    | (lambda docs: \"\\n\".join([doc.page_content for doc in docs]) if docs else \"No relevant legal information found.\")\n",
    ")\n",
    "\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=ChatOllama(model=\"mistral\"),\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "\n",
    "chat_pipeline = (\n",
    "    RunnablePassthrough()\n",
    "    | (lambda query: {\n",
    "        \"history\": \"\\n\".join(\n",
    "            [f\"{msg.type.capitalize()}: {msg.content}\" for msg in ([system_message] + memory.load_memory_variables({}).get(\"history\", []))]\n",
    "        ),\n",
    "        \"retrieved_context\": retriever.invoke(query),\n",
    "        \"query\": query\n",
    "    })\n",
    "    | llm_chain\n",
    "    | (lambda response: response[\"text\"] if isinstance(response, dict) and \"text\" in response else str(response))\n",
    ")\n",
    "\n",
    "\n",
    "def retrieve_and_answer(query):\n",
    "    \"\"\"Retrieve relevant legal information and generate an AI response.\"\"\"\n",
    "    \n",
    "    \n",
    "    retrieved_context = retriever.invoke(query)\n",
    "\n",
    "    \n",
    "    previous_messages = memory.load_memory_variables({}).get(\"history\", [])\n",
    "    \n",
    "    \n",
    "    formatted_history = \"\\n\".join(\n",
    "        [f\"{msg.type.capitalize()}: {msg.content}\" for msg in ([system_message] + previous_messages)]\n",
    "    )\n",
    "\n",
    "    \n",
    "    response = chat_pipeline.invoke({\n",
    "        \"history\": formatted_history,\n",
    "        \"retrieved_context\": retrieved_context,\n",
    "        \"query\": query\n",
    "    })\n",
    "\n",
    "    \n",
    "    memory.save_context({\"input\": query}, {\"output\": response})\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Legal AI Chatbot (Type 'exit' or 'quit' to stop)\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Exiting chatbot. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        ai_response = retrieve_and_answer(user_input)\n",
    "        print(f\"AI: {ai_response}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
